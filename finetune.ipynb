{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cc7ec0d-9120-4569-b5c3-ef7fdb1716b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b47a96b-5eed-4f55-b9c1-d090cec75922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28af8b97-62c2-47c7-94f7-53598ae16d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* CUDA:\n",
      "\t- GPU:\n",
      "\t\t- NVIDIA H100 PCIe\n",
      "\t- available:         True\n",
      "\t- version:           12.1\n",
      "* Packages:\n",
      "\t- numpy:             1.23.1\n",
      "\t- pandas:            1.4.4\n",
      "\t- pyTorch_debug:     False\n",
      "\t- pyTorch_version:   2.3.1+cu121\n",
      "\t- pytorch-lightning: 2.3.3\n",
      "\t- sklearn:           1.3.2\n",
      "\t- transformers:      4.42.4\n",
      "* System:\n",
      "\t- OS:                Linux\n",
      "\t- architecture:\n",
      "\t\t- 64bit\n",
      "\t\t- ELF\n",
      "\t- processor:         x86_64\n",
      "\t- python:            3.10.12\n",
      "\t- ram:               202329743360\n",
      "\t- version:           #10-Ubuntu SMP PREEMPT_DYNAMIC Wed Apr 26 00:40:27 UTC 2023\n"
     ]
    }
   ],
   "source": [
    "from src.env import print_env_details\n",
    "print_env_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c6370a5d-62c0-41c5-9efb-bd3c2e288354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers.utils import is_flash_attn_2_available"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf65595-b0de-48fe-b249-14d4b13f8542",
   "metadata": {},
   "source": [
    "## Load model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "22f80c6f-f370-4352-bad1-5090e4dfd2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"microsoft/Phi-3-mini-4k-instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7d06177e-8db3-49af-9784-04a0b4cdaeeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.model_max_length = 2048\n",
    "tokenizer.pad_token = tokenizer.unk_token  # use unk rather than eos token to prevent endless generation\n",
    "tokenizer.pad_token_id = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
    "tokenizer.padding_side = 'right'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2b6db6e0-a4f3-42d5-aff7-081a9242d8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:01<00:00,  1.48it/s]\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    use_cache=False,\n",
    "    device_map=\"auto\", \n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    attn_implementation=\"flash_attention_2\" if is_flash_attn_2_available() else \"eager\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd220ef-25ef-4b3e-b7b5-cdfa82ab358d",
   "metadata": {},
   "source": [
    "## Process dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8a136c29-cdf9-471d-9f67-4afc02d598dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import load_jsonl\n",
    "\n",
    "samples = list(load_jsonl(\"data/MATH/train_gpt4.jsonl\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "beb0eec3-3ec5-40ac-8883-7d88a4870e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"prompts/python.md\", \"r\") as f:\n",
    "    prompt = f.read()\n",
    "\n",
    "messages = []\n",
    "for s in samples:\n",
    "    messages.append(\n",
    "        {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"content\": f\"{prompt}\\n Question: {s['problem'].strip()}\\n Solution: {s['solution'].strip()}\",\n",
    "                    \"role\": \"user\",\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a9bc68a8-f2d1-4ec4-b92a-5ab90f0952ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=10): 100%|███████████| 7500/7500 [00:02<00:00, 3198.72 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, load_dataset\n",
    "\n",
    "def apply_chat_template(\n",
    "    example,\n",
    "    tokenizer,\n",
    "):\n",
    "    messages = example[\"messages\"]\n",
    "    example[\"text\"] = tokenizer.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=False)\n",
    "    return example\n",
    "\n",
    "train_dataset = Dataset.from_list(messages).map(apply_chat_template, fn_kwargs={\"tokenizer\": tokenizer}, num_proc=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644a0c4e-4241-4f0c-8092-d99877e93590",
   "metadata": {},
   "source": [
    "## Prepare for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f8902de4-383d-4285-9239-38a250b9b8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments, BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "71572655-2f28-4375-9aa6-4a2339478f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_config = {\n",
    "    \"bf16\": True,\n",
    "    \"do_eval\": False,\n",
    "    \"learning_rate\": 2e-5,\n",
    "    \"log_level\": \"info\",\n",
    "    \"logging_steps\": 20,\n",
    "    \"logging_strategy\": \"steps\",\n",
    "    \"lr_scheduler_type\": \"linear\",\n",
    "    \"num_train_epochs\": 3,\n",
    "    \"max_steps\": -1,\n",
    "    \"output_dir\": \"./models\",\n",
    "    \"overwrite_output_dir\": True,\n",
    "    \"per_device_eval_batch_size\": 4,\n",
    "    \"per_device_train_batch_size\": 4,\n",
    "    \"remove_unused_columns\": True,\n",
    "    \"save_steps\": 100,\n",
    "    \"save_total_limit\": 1,\n",
    "    \"seed\": 0,\n",
    "    \"gradient_checkpointing\": True,\n",
    "    \"gradient_checkpointing_kwargs\":{\"use_reentrant\": False},\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"warmup_ratio\": 0.03,\n",
    "    \"optim\": \"adamw_torch_fused\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "13dce107-90e6-469a-8f36-78b853e0bf01",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length, dataset_text_field, packing. Will not be supported from version '1.0.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:192: UserWarning: You passed a `packing` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:280: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "Generating train split: 0 examples [00:00, ? examples/s]Token indices sequence length is longer than the specified maximum sequence length for this model (2686 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Generating train split: 8399 examples [00:19, 430.15 examples/s]\n",
      "Using auto half precision backend\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=TrainingArguments(**training_config),\n",
    "    peft_config=None,\n",
    "    train_dataset=train_dataset,\n",
    "    max_seq_length=2048,\n",
    "    dataset_text_field=\"text\",\n",
    "    tokenizer=tokenizer,\n",
    "    packing=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5a64a0ab-ad25-490d-880d-2a0665e086b6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 8,399\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6,300\n",
      "  Number of trainable parameters = 3,821,079,552\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6300' max='6300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6300/6300 2:24:33, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.671900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.632100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.495100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.299200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.195400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.149900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.143300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.138500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.133600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.122300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.131900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.128400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.131800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.116500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.132800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.125400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.113700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.118000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.124900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.119000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.106700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.129500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.120900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.115300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.123000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.107900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.108400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.114100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.105800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.109800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.115800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.110700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.107300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>0.127900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.128000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.127800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>0.125300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>0.107000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.103200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.105000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>0.106700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.115100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>0.112500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>0.124500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.106200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>0.118300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>0.122800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.110800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>0.113400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.103900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.119600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1040</td>\n",
       "      <td>0.112000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1060</td>\n",
       "      <td>0.109400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.113300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.115100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1120</td>\n",
       "      <td>0.113800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.111700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1160</td>\n",
       "      <td>0.127700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1180</td>\n",
       "      <td>0.109100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.109700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1220</td>\n",
       "      <td>0.111300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1240</td>\n",
       "      <td>0.114900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.119400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1280</td>\n",
       "      <td>0.108300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.102600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.123300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1340</td>\n",
       "      <td>0.115500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1360</td>\n",
       "      <td>0.122700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.110600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.119300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1420</td>\n",
       "      <td>0.111200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.114400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1460</td>\n",
       "      <td>0.116100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1480</td>\n",
       "      <td>0.098400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.111900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1520</td>\n",
       "      <td>0.111300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1540</td>\n",
       "      <td>0.105600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.105400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1580</td>\n",
       "      <td>0.124400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.106300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.111400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1640</td>\n",
       "      <td>0.101800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1660</td>\n",
       "      <td>0.113200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.120600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.114900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1720</td>\n",
       "      <td>0.116100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.115700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1760</td>\n",
       "      <td>0.122200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1780</td>\n",
       "      <td>0.108900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.120600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1820</td>\n",
       "      <td>0.118200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1840</td>\n",
       "      <td>0.116600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.108800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1880</td>\n",
       "      <td>0.120600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.114300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.109200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1940</td>\n",
       "      <td>0.118800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1960</td>\n",
       "      <td>0.107100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1980</td>\n",
       "      <td>0.107900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.103800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020</td>\n",
       "      <td>0.107200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2040</td>\n",
       "      <td>0.110400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2060</td>\n",
       "      <td>0.112900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2080</td>\n",
       "      <td>0.115600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.108000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2120</td>\n",
       "      <td>0.108300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2140</td>\n",
       "      <td>0.108200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2160</td>\n",
       "      <td>0.093700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2180</td>\n",
       "      <td>0.111000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.111300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2220</td>\n",
       "      <td>0.110700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2240</td>\n",
       "      <td>0.103400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2260</td>\n",
       "      <td>0.114500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2280</td>\n",
       "      <td>0.104200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.097500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2320</td>\n",
       "      <td>0.097700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2340</td>\n",
       "      <td>0.096200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2360</td>\n",
       "      <td>0.107500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2380</td>\n",
       "      <td>0.103000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.101900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2420</td>\n",
       "      <td>0.095500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2440</td>\n",
       "      <td>0.100700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2460</td>\n",
       "      <td>0.107400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2480</td>\n",
       "      <td>0.103100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.102300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2520</td>\n",
       "      <td>0.101400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2540</td>\n",
       "      <td>0.101000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2560</td>\n",
       "      <td>0.102800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2580</td>\n",
       "      <td>0.111100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.111800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2620</td>\n",
       "      <td>0.101600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2640</td>\n",
       "      <td>0.109800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2660</td>\n",
       "      <td>0.114900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2680</td>\n",
       "      <td>0.099000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.105200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2720</td>\n",
       "      <td>0.106900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2740</td>\n",
       "      <td>0.098500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2760</td>\n",
       "      <td>0.109000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2780</td>\n",
       "      <td>0.100700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.104100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2820</td>\n",
       "      <td>0.104900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2840</td>\n",
       "      <td>0.096000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2860</td>\n",
       "      <td>0.106700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2880</td>\n",
       "      <td>0.108200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.102000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2920</td>\n",
       "      <td>0.109900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2940</td>\n",
       "      <td>0.102000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2960</td>\n",
       "      <td>0.097400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2980</td>\n",
       "      <td>0.103800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.119200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3020</td>\n",
       "      <td>0.104200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3040</td>\n",
       "      <td>0.099000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3060</td>\n",
       "      <td>0.109100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3080</td>\n",
       "      <td>0.100400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.107500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3120</td>\n",
       "      <td>0.095000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3140</td>\n",
       "      <td>0.106200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3160</td>\n",
       "      <td>0.107100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3180</td>\n",
       "      <td>0.109200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.099300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3220</td>\n",
       "      <td>0.099900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3240</td>\n",
       "      <td>0.106700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3260</td>\n",
       "      <td>0.106300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3280</td>\n",
       "      <td>0.098800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.107900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3320</td>\n",
       "      <td>0.101800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3340</td>\n",
       "      <td>0.100400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3360</td>\n",
       "      <td>0.097400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3380</td>\n",
       "      <td>0.097100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.104900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3420</td>\n",
       "      <td>0.109200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3440</td>\n",
       "      <td>0.107100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3460</td>\n",
       "      <td>0.106700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3480</td>\n",
       "      <td>0.097900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.112600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3520</td>\n",
       "      <td>0.096900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3540</td>\n",
       "      <td>0.097300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3560</td>\n",
       "      <td>0.104800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3580</td>\n",
       "      <td>0.111800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.106600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3620</td>\n",
       "      <td>0.102300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3640</td>\n",
       "      <td>0.095800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3660</td>\n",
       "      <td>0.092100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3680</td>\n",
       "      <td>0.095300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3720</td>\n",
       "      <td>0.106900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3740</td>\n",
       "      <td>0.102200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3760</td>\n",
       "      <td>0.099500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3780</td>\n",
       "      <td>0.104500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.109000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3820</td>\n",
       "      <td>0.106800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3840</td>\n",
       "      <td>0.102100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3860</td>\n",
       "      <td>0.107900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3880</td>\n",
       "      <td>0.096400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.103800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3920</td>\n",
       "      <td>0.105700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3940</td>\n",
       "      <td>0.102300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3960</td>\n",
       "      <td>0.102100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3980</td>\n",
       "      <td>0.092100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.106000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4020</td>\n",
       "      <td>0.100100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4040</td>\n",
       "      <td>0.105900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4060</td>\n",
       "      <td>0.108200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4080</td>\n",
       "      <td>0.102200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.104700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4120</td>\n",
       "      <td>0.099200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4140</td>\n",
       "      <td>0.101300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4160</td>\n",
       "      <td>0.087400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4180</td>\n",
       "      <td>0.094800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.106500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4220</td>\n",
       "      <td>0.103300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4240</td>\n",
       "      <td>0.103500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4260</td>\n",
       "      <td>0.094800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4280</td>\n",
       "      <td>0.091100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.093500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4320</td>\n",
       "      <td>0.100600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4340</td>\n",
       "      <td>0.098900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4360</td>\n",
       "      <td>0.095000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4380</td>\n",
       "      <td>0.102300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.102100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4420</td>\n",
       "      <td>0.103100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4440</td>\n",
       "      <td>0.100800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4460</td>\n",
       "      <td>0.102100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4480</td>\n",
       "      <td>0.124300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.110800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4520</td>\n",
       "      <td>0.103300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4540</td>\n",
       "      <td>0.090900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4560</td>\n",
       "      <td>0.099900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4580</td>\n",
       "      <td>0.113700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.094200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4620</td>\n",
       "      <td>0.089500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4640</td>\n",
       "      <td>0.119100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4660</td>\n",
       "      <td>0.093600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4680</td>\n",
       "      <td>0.093800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>0.101000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4720</td>\n",
       "      <td>0.099900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4740</td>\n",
       "      <td>0.099500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4760</td>\n",
       "      <td>0.105000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4780</td>\n",
       "      <td>0.106600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.101800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4820</td>\n",
       "      <td>0.094300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4840</td>\n",
       "      <td>0.098300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4860</td>\n",
       "      <td>0.101400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4880</td>\n",
       "      <td>0.102500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>0.094600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4920</td>\n",
       "      <td>0.097100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4940</td>\n",
       "      <td>0.097600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4960</td>\n",
       "      <td>0.101900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4980</td>\n",
       "      <td>0.104500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.094100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5020</td>\n",
       "      <td>0.103300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5040</td>\n",
       "      <td>0.107800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5060</td>\n",
       "      <td>0.102100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5080</td>\n",
       "      <td>0.099800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>0.101000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5120</td>\n",
       "      <td>0.097900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5140</td>\n",
       "      <td>0.106500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5160</td>\n",
       "      <td>0.101000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5180</td>\n",
       "      <td>0.096400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.104700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5220</td>\n",
       "      <td>0.106500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5240</td>\n",
       "      <td>0.109900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5260</td>\n",
       "      <td>0.103800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5280</td>\n",
       "      <td>0.101200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5300</td>\n",
       "      <td>0.097400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5320</td>\n",
       "      <td>0.111200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5340</td>\n",
       "      <td>0.109600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5360</td>\n",
       "      <td>0.092800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5380</td>\n",
       "      <td>0.105900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.105000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5420</td>\n",
       "      <td>0.097400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5440</td>\n",
       "      <td>0.104800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5460</td>\n",
       "      <td>0.104600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5480</td>\n",
       "      <td>0.104200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.097400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5520</td>\n",
       "      <td>0.104600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5540</td>\n",
       "      <td>0.096500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5560</td>\n",
       "      <td>0.111300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5580</td>\n",
       "      <td>0.105000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.097000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5620</td>\n",
       "      <td>0.109600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5640</td>\n",
       "      <td>0.099300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5660</td>\n",
       "      <td>0.104700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5680</td>\n",
       "      <td>0.095500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5700</td>\n",
       "      <td>0.110100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5720</td>\n",
       "      <td>0.113400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5740</td>\n",
       "      <td>0.119800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5760</td>\n",
       "      <td>0.096800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5780</td>\n",
       "      <td>0.096900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.104100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5820</td>\n",
       "      <td>0.108500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5840</td>\n",
       "      <td>0.098200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5860</td>\n",
       "      <td>0.092100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5880</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5900</td>\n",
       "      <td>0.092700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5920</td>\n",
       "      <td>0.090700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5940</td>\n",
       "      <td>0.088400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5960</td>\n",
       "      <td>0.100300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5980</td>\n",
       "      <td>0.108700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.096400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6020</td>\n",
       "      <td>0.101400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6040</td>\n",
       "      <td>0.099700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6060</td>\n",
       "      <td>0.095300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6080</td>\n",
       "      <td>0.091400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6100</td>\n",
       "      <td>0.103100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6120</td>\n",
       "      <td>0.093100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6140</td>\n",
       "      <td>0.087500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6160</td>\n",
       "      <td>0.095700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6180</td>\n",
       "      <td>0.113300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.106700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6220</td>\n",
       "      <td>0.096600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6240</td>\n",
       "      <td>0.104800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6260</td>\n",
       "      <td>0.099200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6280</td>\n",
       "      <td>0.103700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6300</td>\n",
       "      <td>0.104900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./models/checkpoint-100\n",
      "Configuration saved in ./models/checkpoint-100/config.json\n",
      "Configuration saved in ./models/checkpoint-100/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-100/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-100/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-100/special_tokens_map.json\n",
      "Saving model checkpoint to ./models/checkpoint-200\n",
      "Configuration saved in ./models/checkpoint-200/config.json\n",
      "Configuration saved in ./models/checkpoint-200/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-200/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-200/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-200/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-100] due to args.save_total_limit\n",
      "Saving model checkpoint to ./models/checkpoint-300\n",
      "Configuration saved in ./models/checkpoint-300/config.json\n",
      "Configuration saved in ./models/checkpoint-300/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-300/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-300/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-300/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-200] due to args.save_total_limit\n",
      "Saving model checkpoint to ./models/checkpoint-400\n",
      "Configuration saved in ./models/checkpoint-400/config.json\n",
      "Configuration saved in ./models/checkpoint-400/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-400/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-400/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-400/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-300] due to args.save_total_limit\n",
      "Saving model checkpoint to ./models/checkpoint-500\n",
      "Configuration saved in ./models/checkpoint-500/config.json\n",
      "Configuration saved in ./models/checkpoint-500/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-500/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-500/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-400] due to args.save_total_limit\n",
      "Saving model checkpoint to ./models/checkpoint-600\n",
      "Configuration saved in ./models/checkpoint-600/config.json\n",
      "Configuration saved in ./models/checkpoint-600/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-600/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-600/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-600/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./models/checkpoint-700\n",
      "Configuration saved in ./models/checkpoint-700/config.json\n",
      "Configuration saved in ./models/checkpoint-700/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-700/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-700/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-700/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-600] due to args.save_total_limit\n",
      "Saving model checkpoint to ./models/checkpoint-800\n",
      "Configuration saved in ./models/checkpoint-800/config.json\n",
      "Configuration saved in ./models/checkpoint-800/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-800/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-800/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-800/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-700] due to args.save_total_limit\n",
      "Saving model checkpoint to ./models/checkpoint-900\n",
      "Configuration saved in ./models/checkpoint-900/config.json\n",
      "Configuration saved in ./models/checkpoint-900/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-900/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-900/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-900/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-800] due to args.save_total_limit\n",
      "Saving model checkpoint to ./models/checkpoint-1000\n",
      "Configuration saved in ./models/checkpoint-1000/config.json\n",
      "Configuration saved in ./models/checkpoint-1000/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-1000/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-1000/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-900] due to args.save_total_limit\n",
      "Saving model checkpoint to ./models/checkpoint-1100\n",
      "Configuration saved in ./models/checkpoint-1100/config.json\n",
      "Configuration saved in ./models/checkpoint-1100/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-1100/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-1100/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-1100/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-1000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./models/checkpoint-1200\n",
      "Configuration saved in ./models/checkpoint-1200/config.json\n",
      "Configuration saved in ./models/checkpoint-1200/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-1200/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-1200/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-1200/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-1100] due to args.save_total_limit\n",
      "Saving model checkpoint to ./models/checkpoint-1300\n",
      "Configuration saved in ./models/checkpoint-1300/config.json\n",
      "Configuration saved in ./models/checkpoint-1300/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-1300/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-1300/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-1300/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-1200] due to args.save_total_limit\n",
      "Saving model checkpoint to ./models/checkpoint-1400\n",
      "Configuration saved in ./models/checkpoint-1400/config.json\n",
      "Configuration saved in ./models/checkpoint-1400/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-1400/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-1400/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-1400/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-1300] due to args.save_total_limit\n",
      "Saving model checkpoint to ./models/checkpoint-1500\n",
      "Configuration saved in ./models/checkpoint-1500/config.json\n",
      "Configuration saved in ./models/checkpoint-1500/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-1500/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-1500/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-1400] due to args.save_total_limit\n",
      "Saving model checkpoint to ./models/checkpoint-1600\n",
      "Configuration saved in ./models/checkpoint-1600/config.json\n",
      "Configuration saved in ./models/checkpoint-1600/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-1600/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-1600/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-1600/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-1500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./models/checkpoint-1700\n",
      "Configuration saved in ./models/checkpoint-1700/config.json\n",
      "Configuration saved in ./models/checkpoint-1700/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-1700/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-1700/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-1700/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-1600] due to args.save_total_limit\n",
      "Saving model checkpoint to ./models/checkpoint-1800\n",
      "Configuration saved in ./models/checkpoint-1800/config.json\n",
      "Configuration saved in ./models/checkpoint-1800/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-1800/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-1800/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-1800/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-1700] due to args.save_total_limit\n",
      "Saving model checkpoint to ./models/checkpoint-1900\n",
      "Configuration saved in ./models/checkpoint-1900/config.json\n",
      "Configuration saved in ./models/checkpoint-1900/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-1900/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-1900/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-1900/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-1800] due to args.save_total_limit\n",
      "Saving model checkpoint to ./models/checkpoint-2000\n",
      "Configuration saved in ./models/checkpoint-2000/config.json\n",
      "Configuration saved in ./models/checkpoint-2000/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-2000/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-2000/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-1900] due to args.save_total_limit\n",
      "Saving model checkpoint to ./models/checkpoint-2100\n",
      "Configuration saved in ./models/checkpoint-2100/config.json\n",
      "Configuration saved in ./models/checkpoint-2100/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-2100/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-2100/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-2100/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-2000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./models/checkpoint-2200\n",
      "Configuration saved in ./models/checkpoint-2200/config.json\n",
      "Configuration saved in ./models/checkpoint-2200/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-2200/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-2200/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-2200/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-2100] due to args.save_total_limit\n",
      "Saving model checkpoint to ./models/checkpoint-2300\n",
      "Configuration saved in ./models/checkpoint-2300/config.json\n",
      "Configuration saved in ./models/checkpoint-2300/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-2300/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-2300/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-2300/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-2200] due to args.save_total_limit\n",
      "Saving model checkpoint to ./models/checkpoint-2400\n",
      "Configuration saved in ./models/checkpoint-2400/config.json\n",
      "Configuration saved in ./models/checkpoint-2400/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-2400/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-2400/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-2400/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-2300] due to args.save_total_limit\n",
      "Saving model checkpoint to ./models/checkpoint-2500\n",
      "Configuration saved in ./models/checkpoint-2500/config.json\n",
      "Configuration saved in ./models/checkpoint-2500/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-2500/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-2500/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-2400] due to args.save_total_limit\n",
      "Saving model checkpoint to ./models/checkpoint-2600\n",
      "Configuration saved in ./models/checkpoint-2600/config.json\n",
      "Configuration saved in ./models/checkpoint-2600/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-2600/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-2600/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-2600/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-2500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./models/checkpoint-2700\n",
      "Configuration saved in ./models/checkpoint-2700/config.json\n",
      "Configuration saved in ./models/checkpoint-2700/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-2700/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-2700/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-2700/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-2600] due to args.save_total_limit\n",
      "Saving model checkpoint to ./models/checkpoint-2800\n",
      "Configuration saved in ./models/checkpoint-2800/config.json\n",
      "Configuration saved in ./models/checkpoint-2800/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-2800/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-2800/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-2800/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-2700] due to args.save_total_limit\n",
      "Saving model checkpoint to ./models/checkpoint-2900\n",
      "Configuration saved in ./models/checkpoint-2900/config.json\n",
      "Configuration saved in ./models/checkpoint-2900/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-2900/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-2900/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-2900/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-2800] due to args.save_total_limit\n",
      "Saving model checkpoint to ./models/checkpoint-3000\n",
      "Configuration saved in ./models/checkpoint-3000/config.json\n",
      "Configuration saved in ./models/checkpoint-3000/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-3000/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-3000/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-2900] due to args.save_total_limit\n",
      "Saving model checkpoint to ./models/checkpoint-3100\n",
      "Configuration saved in ./models/checkpoint-3100/config.json\n",
      "Configuration saved in ./models/checkpoint-3100/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-3100/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-3100/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-3100/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-3000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./models/checkpoint-3200\n",
      "Configuration saved in ./models/checkpoint-3200/config.json\n",
      "Configuration saved in ./models/checkpoint-3200/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-3200/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-3200/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-3200/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-3100] due to args.save_total_limit\n",
      "Saving model checkpoint to ./models/checkpoint-3300\n",
      "Configuration saved in ./models/checkpoint-3300/config.json\n",
      "Configuration saved in ./models/checkpoint-3300/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-3300/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-3300/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-3300/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-3200] due to args.save_total_limit\n",
      "Saving model checkpoint to ./models/checkpoint-3400\n",
      "Configuration saved in ./models/checkpoint-3400/config.json\n",
      "Configuration saved in ./models/checkpoint-3400/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-3400/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-3400/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-3400/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-3300] due to args.save_total_limit\n",
      "Saving model checkpoint to ./models/checkpoint-3500\n",
      "Configuration saved in ./models/checkpoint-3500/config.json\n",
      "Configuration saved in ./models/checkpoint-3500/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-3500/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-3500/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-3500/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-3400] due to args.save_total_limit\n",
      "Saving model checkpoint to ./models/checkpoint-3600\n",
      "Configuration saved in ./models/checkpoint-3600/config.json\n",
      "Configuration saved in ./models/checkpoint-3600/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-3600/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-3600/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-3600/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-3500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./models/checkpoint-3700\n",
      "Configuration saved in ./models/checkpoint-3700/config.json\n",
      "Configuration saved in ./models/checkpoint-3700/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-3700/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-3700/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-3700/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-3600] due to args.save_total_limit\n",
      "Saving model checkpoint to ./models/checkpoint-3800\n",
      "Configuration saved in ./models/checkpoint-3800/config.json\n",
      "Configuration saved in ./models/checkpoint-3800/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-3800/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-3800/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-3800/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-3700] due to args.save_total_limit\n",
      "Saving model checkpoint to ./models/checkpoint-3900\n",
      "Configuration saved in ./models/checkpoint-3900/config.json\n",
      "Configuration saved in ./models/checkpoint-3900/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-3900/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-3900/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-3900/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-3800] due to args.save_total_limit\n",
      "Saving model checkpoint to ./models/checkpoint-4000\n",
      "Configuration saved in ./models/checkpoint-4000/config.json\n",
      "Configuration saved in ./models/checkpoint-4000/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-4000/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-4000/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-3900] due to args.save_total_limit\n",
      "Saving model checkpoint to ./models/checkpoint-4100\n",
      "Configuration saved in ./models/checkpoint-4100/config.json\n",
      "Configuration saved in ./models/checkpoint-4100/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-4100/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-4100/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-4100/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-4000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./models/checkpoint-4200\n",
      "Configuration saved in ./models/checkpoint-4200/config.json\n",
      "Configuration saved in ./models/checkpoint-4200/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-4200/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-4200/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-4200/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-4100] due to args.save_total_limit\n",
      "Saving model checkpoint to ./models/checkpoint-4300\n",
      "Configuration saved in ./models/checkpoint-4300/config.json\n",
      "Configuration saved in ./models/checkpoint-4300/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-4300/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-4300/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-4300/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-4200] due to args.save_total_limit\n",
      "Saving model checkpoint to ./models/checkpoint-4400\n",
      "Configuration saved in ./models/checkpoint-4400/config.json\n",
      "Configuration saved in ./models/checkpoint-4400/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-4400/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-4400/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-4400/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-4300] due to args.save_total_limit\n",
      "Saving model checkpoint to ./models/checkpoint-4500\n",
      "Configuration saved in ./models/checkpoint-4500/config.json\n",
      "Configuration saved in ./models/checkpoint-4500/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-4500/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-4500/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-4500/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-4400] due to args.save_total_limit\n",
      "Saving model checkpoint to ./models/checkpoint-4600\n",
      "Configuration saved in ./models/checkpoint-4600/config.json\n",
      "Configuration saved in ./models/checkpoint-4600/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-4600/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-4600/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-4600/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-4500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./models/checkpoint-4700\n",
      "Configuration saved in ./models/checkpoint-4700/config.json\n",
      "Configuration saved in ./models/checkpoint-4700/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-4700/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-4700/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-4700/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-4600] due to args.save_total_limit\n",
      "Saving model checkpoint to ./models/checkpoint-4800\n",
      "Configuration saved in ./models/checkpoint-4800/config.json\n",
      "Configuration saved in ./models/checkpoint-4800/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-4800/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-4800/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-4800/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-4700] due to args.save_total_limit\n",
      "Saving model checkpoint to ./models/checkpoint-4900\n",
      "Configuration saved in ./models/checkpoint-4900/config.json\n",
      "Configuration saved in ./models/checkpoint-4900/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-4900/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-4900/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-4900/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-4800] due to args.save_total_limit\n",
      "Saving model checkpoint to ./models/checkpoint-5000\n",
      "Configuration saved in ./models/checkpoint-5000/config.json\n",
      "Configuration saved in ./models/checkpoint-5000/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-5000/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-5000/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-4900] due to args.save_total_limit\n",
      "Saving model checkpoint to ./models/checkpoint-5100\n",
      "Configuration saved in ./models/checkpoint-5100/config.json\n",
      "Configuration saved in ./models/checkpoint-5100/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-5100/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-5100/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-5100/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-5000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./models/checkpoint-5200\n",
      "Configuration saved in ./models/checkpoint-5200/config.json\n",
      "Configuration saved in ./models/checkpoint-5200/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-5200/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-5200/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-5200/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-5100] due to args.save_total_limit\n",
      "Saving model checkpoint to ./models/checkpoint-5300\n",
      "Configuration saved in ./models/checkpoint-5300/config.json\n",
      "Configuration saved in ./models/checkpoint-5300/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-5300/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-5300/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-5300/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-5200] due to args.save_total_limit\n",
      "Saving model checkpoint to ./models/checkpoint-5400\n",
      "Configuration saved in ./models/checkpoint-5400/config.json\n",
      "Configuration saved in ./models/checkpoint-5400/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-5400/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-5400/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-5400/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-5300] due to args.save_total_limit\n",
      "Saving model checkpoint to ./models/checkpoint-5500\n",
      "Configuration saved in ./models/checkpoint-5500/config.json\n",
      "Configuration saved in ./models/checkpoint-5500/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-5500/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-5500/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-5500/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-5400] due to args.save_total_limit\n",
      "Saving model checkpoint to ./models/checkpoint-5600\n",
      "Configuration saved in ./models/checkpoint-5600/config.json\n",
      "Configuration saved in ./models/checkpoint-5600/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-5600/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-5600/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-5600/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-5500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./models/checkpoint-5700\n",
      "Configuration saved in ./models/checkpoint-5700/config.json\n",
      "Configuration saved in ./models/checkpoint-5700/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-5700/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-5700/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-5700/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-5600] due to args.save_total_limit\n",
      "Saving model checkpoint to ./models/checkpoint-5800\n",
      "Configuration saved in ./models/checkpoint-5800/config.json\n",
      "Configuration saved in ./models/checkpoint-5800/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-5800/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-5800/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-5800/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-5700] due to args.save_total_limit\n",
      "Saving model checkpoint to ./models/checkpoint-5900\n",
      "Configuration saved in ./models/checkpoint-5900/config.json\n",
      "Configuration saved in ./models/checkpoint-5900/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-5900/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-5900/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-5900/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-5800] due to args.save_total_limit\n",
      "Saving model checkpoint to ./models/checkpoint-6000\n",
      "Configuration saved in ./models/checkpoint-6000/config.json\n",
      "Configuration saved in ./models/checkpoint-6000/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-6000/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-6000/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-6000/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-5900] due to args.save_total_limit\n",
      "Saving model checkpoint to ./models/checkpoint-6100\n",
      "Configuration saved in ./models/checkpoint-6100/config.json\n",
      "Configuration saved in ./models/checkpoint-6100/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-6100/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-6100/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-6100/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-6000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./models/checkpoint-6200\n",
      "Configuration saved in ./models/checkpoint-6200/config.json\n",
      "Configuration saved in ./models/checkpoint-6200/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-6200/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-6200/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-6200/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-6100] due to args.save_total_limit\n",
      "Saving model checkpoint to ./models/checkpoint-6300\n",
      "Configuration saved in ./models/checkpoint-6300/config.json\n",
      "Configuration saved in ./models/checkpoint-6300/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./models/checkpoint-6300/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./models/checkpoint-6300/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-6300/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-6200] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_result = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b3183df9-430b-4248-bf72-fc7c6dae8e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to models/phi3_ft\n",
      "Configuration saved in models/phi3_ft/config.json\n",
      "Configuration saved in models/phi3_ft/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at models/phi3_ft/model.safetensors.index.json.\n",
      "tokenizer config file saved in models/phi3_ft/tokenizer_config.json\n",
      "Special tokens file saved in models/phi3_ft/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(\"models/phi3_ft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ca9803a9-e828-4ea4-91aa-907175d6b509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.push_to_hub(\"parasdahal/Phi-3-mini-4k-instruct-finetuned_MATH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "80399ffd-fb78-4b5b-9008-2207f86355b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "del trainer\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
